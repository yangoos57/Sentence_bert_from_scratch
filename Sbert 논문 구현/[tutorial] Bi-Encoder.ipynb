{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Bert ë…¼ë¬¸ í•µì‹¬ ìš”ì•½\n",
    "\n",
    "- Bert ëª¨ë¸ì„ í™œìš©í•´ Sentence Embeddingì„ ì‚°ì¶œí•˜ëŠ” ëª¨ë¸ ì†Œê°œ\n",
    "\n",
    "- ë°ì´í„° ìœ í˜•(`Categorical Data`, `Numerical Data`)ì— ë§ê²Œ ì–¸ì–´ ëª¨ë¸ì„ Sentence Bertë¡œ Fine-tuningí•˜ëŠ” ë°©ë²• ì†Œê°œ\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Siamese Network(ìƒ´ ë„¤íŠ¸ì›Œí¬)\n",
    "\n",
    "- Bi eoncoderëŠ” ìƒ´ ë„¤íŠ¸ì›Œí¬ êµ¬ì¡°ë¥¼ ì·¨í•¨. ìƒ´ ë„¤íŠ¸ì›Œí¬(Siamese network)ë€ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ë‘ ê°œì˜ outputì„ ì‚°ì¶œí•˜ëŠ” êµ¬ì¡°ë¥¼ ì˜ë¯¸í•¨.\n",
    "\n",
    "- ì•„ë˜ êµ¬ì¡°ë¥¼ ë³´ë©´ Bert ëª¨ë¸ì´ ë‘ ê°œ ì‚¬ìš©ë˜ëŠ” ê²ƒìœ¼ë¡œ ë‚˜íƒ€ë‚˜ì§€ë§Œ ì‹¤ì œë¡œëŠ” í•˜ë‚˜ì˜ Bert ëª¨ë¸ì„ í™œìš©í•´ ê°œë³„ ë¬¸ì¥ì˜ outputì„ ì‚°ì¶œí•˜ê²Œ ë¨.\n",
    "\n",
    "    <img src ='../images/SBERT_Siamese_Network.png' alt='SBERT_Siamese_Network' width ='300px'/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi encoder êµ¬í˜„í•˜ê¸°\n",
    "\n",
    "- ì—¬ëŠ Fine-tuning ë°©ë²•ê³¼ ê°™ì´ last_hidden_stateë¥¼ í™œìš©í•´ Bi-encoder êµ¬í˜„í•¨.\n",
    "\n",
    "- Bert ëª¨ë¸ì„ ê±°ì¹œ ë¬¸ì¥ì€ ë¬¸ì¥ì˜ Token ê°œìˆ˜ ë§Œí¼ì˜ Embeddingì´ ì¡´ì¬í•¨. ì´ë•Œ ì—¬ëŸ¬ ê°œì˜ Embeddingì„ í•˜ë‚˜ì˜ Embeddingìœ¼ë¡œ í†µí•©í•˜ëŠ” ê³¼ì •ì„ Poolingì´ë¼ í•˜ëŠ”ë°, ì—¬ëŸ¬ ê°œì˜ í† í° ì„ë² ë”©ì„ í•˜ë‚˜ì˜ Embeddingìœ¼ë¡œ ë³€í™˜í•˜ë©´ Sentence Embeddingì´ ë¨.\n",
    "\n",
    "- Pooling ë°©ë²•ì—ëŠ” [CLS] pooling, mean pooling, max poolingì´ í™œìš© ê°€ëŠ¥í•˜ë‚˜ ë…¼ë¬¸ì—ì„œëŠ” mean poolingì´ ê°€ì¥ ì„±ëŠ¥ì´ ì¢‹ì•„ ê¸°ë³¸ ê°’ìœ¼ë¡œ í™œìš©í•¨. \n",
    "\n",
    "\n",
    "\n",
    "    <img src ='../images/SBERT_Architecture.png' alt='SBERT_Architecture' width ='150px'/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentece Bert êµ¬ì¡° ìƒì„±\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at monologg/koelectra-base-v3-discriminator were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.weight']\n",
      "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing ê²°ê³¼ \n",
      " ['ë‚˜', '##ëŠ”', 'ì–´ì œ', 'ë§¥', '##ë¶', '##ì„', 'ìƒ€', '##ë‹¤', '.']\n",
      "\n",
      "PLM output shape => torch.Size([1, 11, 768]) \n",
      "Sbert output shape => torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    ElectraModel,\n",
    "    ElectraTokenizerFast,\n",
    "    TrainingArguments,\n",
    "    TrainerCallback,\n",
    "    Trainer,\n",
    ")\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import Dataset\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "\n",
    "class SentenceBert(nn.Module):\n",
    "    \"\"\"\n",
    "    Sentence Bert ë…¼ë¬¸ì„ ì½ê³  ê´€ë ¨ Repoë¥¼ ì°¸ê³ í•´ ë§Œë“  ëª¨ë¸ì…ë‹ˆë‹¤.\n",
    "\n",
    "    Huggingface Trainer APIë¥¼ ì‰½ê²Œ í™œìš©í•  ìˆ˜ ìˆë„ë¡ ëª¨ë¸ì„ ì¼ë¶€ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "    Parameter\n",
    "    ---------\n",
    "    - model : Huggingfaceì—ì„œ ì œê³µí•˜ëŠ” BaseModelì„ í™œìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    - tokenizer : ëª¨ë¸ì— ë§ëŠ” í† í¬ë‚˜ì´ì €ë¥¼ ì‚¬ìš©í•´ì•¼í•˜ë©° TokenizerFastë¥¼ í†µí•´ ë¶ˆëŸ¬ì™€ì•¼í•©ë‹ˆë‹¤.\n",
    "    - model ë° tokenizer ì„¤ì •ì´ ì—†ëŠ” ê²½ìš° \"monologg/koelectra-base-v3-discriminator\" ë¥¼ ê¸°ë³¸ ëª¨ë¸ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "    - pooling_type : ë…¼ë¬¸ì—ì„œ ì œì‹œí•˜ëŠ” Pooling ë°©ë²•ì¸ mean pooling, max pooling, CLS poolingì„ ì§€ì›í•˜ë©° ê¸°ë³¸ ì„¤ì • ê°’ì€ meanì…ë‹ˆë‹¤.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model=None, pooling_type: str = \"mean\") -> None:\n",
    "        super().__init__()\n",
    "        name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "        self.model = model if model else ElectraModel.from_pretrained(name)\n",
    "\n",
    "        if pooling_type in [\"mean\", \"max\", \"cls\"] and type(pooling_type) == str:\n",
    "            self.pooling_type = pooling_type\n",
    "        else:\n",
    "            raise ValueError(\"'pooling_type' only ['mean','max','cls'] possible\")\n",
    "\n",
    "    def forward(self, **kwargs):\n",
    "        attention_mask = kwargs[\"attention_mask\"]\n",
    "        last_hidden_state = self.model(**kwargs)[\"last_hidden_state\"]\n",
    "\n",
    "        if self.pooling_type == \"cls\":\n",
    "            \"\"\"[cls] tokenì„ sentence embeddingìœ¼ë¡œ í™œìš©\"\"\"\n",
    "            result = last_hidden_state[:, 0]\n",
    "\n",
    "        if self.pooling_type == \"max\":\n",
    "            \"\"\"ë¬¸ì¥ ë‚´ ì—¬ëŸ¬ í† í° ì¤‘ ê°€ì¥ ê°’ì´ í° tokenë§Œ ì¶”ì¶œí•˜ì—¬ sentence embeddingìœ¼ë¡œ í™œìš©\"\"\"\n",
    "\n",
    "            num_of_tokens = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "            last_hidden_state[num_of_tokens == 0] = -1e9\n",
    "            result = torch.max(last_hidden_state, 1)[0]\n",
    "\n",
    "        if self.pooling_type == \"mean\":\n",
    "            \"\"\"ë¬¸ì¥ ë‚´ í† í°ì„ í‰ê· í•˜ì—¬ sentence embeddingìœ¼ë¡œ í™œìš©\"\"\"\n",
    "\n",
    "            num_of_tokens = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n",
    "\n",
    "            sum_embeddings = torch.sum(last_hidden_state * num_of_tokens, 1)\n",
    "\n",
    "            total_num_of_tokens = num_of_tokens.sum(1)\n",
    "            total_num_of_tokens = torch.clamp(total_num_of_tokens, min=1e-9)\n",
    "\n",
    "            result = sum_embeddings / total_num_of_tokens\n",
    "\n",
    "        return {\"sentence_embedding\": result}\n",
    "\n",
    "\n",
    "### Sbert ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "name = \"monologg/koelectra-base-v3-discriminator\"\n",
    "model = ElectraModel.from_pretrained(name)\n",
    "tokenizer = ElectraTokenizerFast.from_pretrained(name)\n",
    "\n",
    "sbert = SentenceBert(model=model, pooling_type=\"mean\")\n",
    "\n",
    "sen = \"ë‚˜ëŠ” ì–´ì œ ë§¥ë¶ì„ ìƒ€ë‹¤.\"\n",
    "\n",
    "token = tokenizer(sen, return_tensors=\"pt\")\n",
    "PLM = model(**token)[\"last_hidden_state\"]\n",
    "sentence_embedding = sbert(**token)[\"sentence_embedding\"]\n",
    "\n",
    "print(\"Tokenizing ê²°ê³¼ \\n\", tokenizer.tokenize(sen))\n",
    "print(\"\")\n",
    "print(f\"PLM output shape => {PLM.shape} \\nSbert output shape => {sentence_embedding.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ë°ì´í„° ìœ í˜• ë³„ Sentence Bert í•™ìŠµ êµ¬ì¡°\n",
    "\n",
    "- SentenceBertë¥¼ í•™ìŠµ ì‹œí‚¤ëŠ” ë°©ë²•ì€ í•™ìŠµ ë°ì´í„°ì˜ ìœ í˜•ì— ë”°ë¼ ë‹¬ë¼ì§\n",
    "\n",
    "- `Numerical Data`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Sentence Bertë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²½ìš° í•™ìŠµ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ.\n",
    "\n",
    "    <img src ='../images/SBERT_Siamese_Network.png' alt='SBERT_Siamese_Network' width ='300px'/>\n",
    "\n",
    "<br/>\n",
    "\n",
    "- `Categorical Data`ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Sentence Bertë¥¼ í•™ìŠµì‹œí‚¤ëŠ” ê²½ìš° í•™ìŠµ êµ¬ì¡°ëŠ” ë‹¤ìŒê³¼ ê°™ìŒ.\n",
    "\n",
    "    <img src ='../images/SBERT_SoftmaxLoss.png' alt='SBERT_SoftmaxLoss' width ='300px'/>\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Data í•™ìŠµ ì‹œ Sbert êµ¬ì¡°\n",
    "\n",
    "- ë…¼ë¬¸ì—ì„œëŠ” Numerical Data ë°ì´í„°ë¡œ STS ë°ì´í„°ë¥¼ í™œìš©í•¨. ì´ ê¸€ì—ì„œëŠ” `KorSTS` ë°ì´í„°ë¥¼ í™œìš©í•¨.\n",
    "\n",
    "- STS ë°ì´í„°ëŠ” ë¬¸ì¥ 2ê°œì™€ ë¬¸ì¥ì˜ ìœ ì‚¬ë„ë¥¼ í‘œí˜„í•œ ê°’ìœ¼ë¡œ êµ¬ì„±ë¨.\n",
    "\n",
    "  ```python\n",
    "\n",
    "  {\n",
    "  'sen1': 'ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.',\n",
    "  'sen2': 'ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.',\n",
    "  'score': '5.000'\n",
    "  }\n",
    "\n",
    "  ```\n",
    "\n",
    "- í•™ìŠµì´ ì™„ë£Œëœ ì´í›„ì—ëŠ” í•™ìŠµ êµ¬ì¡°ì—ì„œ Sbertë¥¼ ì¶”ì¶œí•˜ì—¬ í™œìš©í•¨.\n",
    "\n",
    "    <img src='../images/SBERT_Siamese_Network.png' alt='siamese' width='300px'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelForRegressionTraining(nn.Module):\n",
    "    def __init__(self, model, *inputs, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # í•™ìŠµì„ ìˆ˜í–‰í•  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, features, answer):\n",
    "\n",
    "        # Sentence 1, Sentence 2ì— ëŒ€í•œ Sentence Embedding í™•ë³´\n",
    "        embeddings = [self.model(**input_data)[\"sentence_embedding\"] for input_data in features]\n",
    "\n",
    "        u, v = embeddings[0], embeddings[1]\n",
    "\n",
    "        # Sentence 1, Sentence 2ì— ëŒ€í•œ Cosine Similarity ê³„ì‚°\n",
    "        cos_score_transformation = nn.Identity()\n",
    "        outputs = cos_score_transformation(torch.cosine_similarity(u, v))\n",
    "\n",
    "        # label score Normalization\n",
    "        answer = answer / 5  # 0 ~ 5 => 0 ~ 1\n",
    "\n",
    "        loss_fct = nn.MSELoss()\n",
    "        loss = loss_fct(outputs, answer.view(-1))\n",
    "\n",
    "        return {\"loss\": loss}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KorSTS Data ë¶ˆëŸ¬ì˜¤ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sen1</th>\n",
       "      <th>sen2</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>5.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>í•œ ë‚¨ìê°€ í° í”Œë£¨íŠ¸ë¥¼ ì—°ì£¼í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>ë‚¨ìê°€ í”Œë£¨íŠ¸ë¥¼ ì—°ì£¼í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>í•œ ë‚¨ìê°€ í”¼ìì— ì¹˜ì¦ˆë¥¼ ë¿Œë ¤ë†“ê³  ìˆë‹¤.</td>\n",
       "      <td>í•œ ë‚¨ìê°€ êµ¬ìš´ í”¼ìì— ì¹˜ì¦ˆ ì¡°ê°ì„ ë¿Œë ¤ë†“ê³  ìˆë‹¤.</td>\n",
       "      <td>3.800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sen1                          sen2  score\n",
       "0           ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.                 ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.  5.000\n",
       "1   í•œ ë‚¨ìê°€ í° í”Œë£¨íŠ¸ë¥¼ ì—°ì£¼í•˜ê³  ìˆë‹¤.             ë‚¨ìê°€ í”Œë£¨íŠ¸ë¥¼ ì—°ì£¼í•˜ê³  ìˆë‹¤.  3.800\n",
       "2  í•œ ë‚¨ìê°€ í”¼ìì— ì¹˜ì¦ˆë¥¼ ë¿Œë ¤ë†“ê³  ìˆë‹¤.  í•œ ë‚¨ìê°€ êµ¬ìš´ í”¼ìì— ì¹˜ì¦ˆ ì¡°ê°ì„ ë¿Œë ¤ë†“ê³  ìˆë‹¤.  3.800"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/KorSTS/sts-train.tsv\") as f:\n",
    "    v = f.readlines()\n",
    "\n",
    "## from list to dataframe\n",
    "lst = [i.rstrip(\"\\n\").split(\"\\t\") for i in v]\n",
    "\n",
    "data = pd.DataFrame(lst[1:], columns=lst[:1])\n",
    "data = data[[\"sentence1\", \"sentence2\", \"score\"]]\n",
    "data.columns = [\"sen1\", \"sen2\", \"score\"]\n",
    "data.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Datasetsìœ¼ë¡œ ë³€í™˜\n",
    "\n",
    "- ğŸ¤—Transformersì™€ í˜¸í™˜ì„ ìœ„í•´ Dataframeì„ ğŸ¤—datasetìœ¼ë¡œ ë³€í™˜\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sen1': 'ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.', 'sen2': 'ë¹„í–‰ê¸°ê°€ ì´ë¥™í•˜ê³  ìˆë‹¤.', 'score': '5.000'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set = Dataset.from_pandas(data)\n",
    "\n",
    "train_data_set[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collator êµ¬í˜„\n",
    "\n",
    "- í•™ìŠµ êµ¬ì¡°ì— ë§ëŠ” input data ìƒì„±ì„ ìœ„í•œ custom collator ì œì‘\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_batching_collate(batch):\n",
    "    text_lst1 = []\n",
    "    text_lst2 = []\n",
    "    labels = []\n",
    "\n",
    "    for example in batch:\n",
    "        for k, v in example.items():\n",
    "            if k == \"sen1\":\n",
    "                text_lst1.append(v)\n",
    "            if k == \"sen2\":\n",
    "                text_lst2.append(v)\n",
    "            if k == \"score\":\n",
    "                labels.append(float(v))\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    sentence_features = []\n",
    "    for items in [text_lst1, text_lst2]:\n",
    "        token = tokenizer(items, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        sentence_features.append(token)\n",
    "\n",
    "    return dict(features=sentence_features, answer=labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤—Transformers Trainerë¥¼ í™œìš©í•´ í•™ìŠµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Option ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# í•™ìŠµ êµ¬ì¡° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_for_training = modelForRegressionTraining(sbert)\n",
    "\n",
    "# Trainer ì •ì˜\n",
    "trainer = Trainer(\n",
    "    model=model_for_training,\n",
    "    train_dataset=train_data_set,\n",
    "    args=training_args,\n",
    "    data_collator=smart_batching_collate,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Data í•™ìŠµ ì‹œ Sbert êµ¬ì¡°\n",
    "\n",
    "- ë…¼ë¬¸ì—ì„œëŠ” Categorical Dataë¡œ NLI ë°ì´í„°ë¥¼ í™œìš©í•¨. ì´ ê¸€ì—ì„œëŠ” `KorNLI` ë°ì´í„° ì¤‘ `snli_1.0_train.ko`ë¥¼ í™œìš©í•¨.\n",
    "\n",
    "- KorNLI ë°ì´í„°ëŠ” ë¬¸ì¥ 2ê°œì™€ ë¬¸ì¥ì˜ ê´€ê³„ë¥¼ Labelë¡œ í‘œí˜„í•¨.\n",
    "\n",
    "```python\n",
    "\n",
    "  {\n",
    "   'sen1': 'ê·¸ë¦¬ê³  ê·¸ê°€ ë§í–ˆë‹¤, \"ì—„ë§ˆ, ì € ì™”ì–´ìš”.\"',\n",
    "   'sen2': 'ê·¸ëŠ” í•™êµ ë²„ìŠ¤ê°€ ê·¸ë¥¼ ë‚´ë ¤ì£¼ìë§ˆì ì—„ë§ˆì—ê²Œ ì „í™”ë¥¼ ê±¸ì—ˆë‹¤.',\n",
    "   'gold_label': 'neutral'\n",
    "   }\n",
    "\n",
    "```\n",
    "\n",
    "- í•™ìŠµì´ ì™„ë£Œëœ ì´í›„ì—ëŠ” í•™ìŠµ êµ¬ì¡°ì—ì„œ Sbertë¥¼ ì¶”ì¶œí•˜ì—¬ í™œìš©í•¨.\n",
    "\n",
    "    <img src='../images/SBERT_SoftmaxLoss.png' alt='siamese' width='300px'>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class modelForClassificationTraining(nn.Module):\n",
    "    def __init__(self, model, *inputs, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        # í•™ìŠµí•  ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "        self.model = model\n",
    "\n",
    "        # ëª¨ë¸ embed_size\n",
    "        sentence_embedding_dimension = self.model.model.config.hidden_size\n",
    "\n",
    "        # concat í•´ì•¼í•˜ëŠ” vector ê°œìˆ˜(U,V, |U-V|)\n",
    "        num_vectors_concatenated = 3\n",
    "\n",
    "        # embed_size * 3 => 3 ì°¨ì›ìœ¼ë¡œ ì¶•ì†Œì‹œí‚¤ëŠ” classifier\n",
    "        self.classifier = nn.Linear(num_vectors_concatenated * sentence_embedding_dimension, 3)\n",
    "\n",
    "    def forward(self, features, answer):\n",
    "\n",
    "        # Sentence Embedding ìƒì„±\n",
    "        embeddings = [self.model(**input_data)[\"sentence_embedding\"] for input_data in features]\n",
    "\n",
    "        u, v = embeddings\n",
    "\n",
    "        # U,V, |U-V| vector ë³‘í•©\n",
    "        vectors_concat = []\n",
    "        vectors_concat.append(u)\n",
    "        vectors_concat.append(v)\n",
    "        vectors_concat.append(torch.abs(u - v))\n",
    "        features = torch.cat(vectors_concat, 1)\n",
    "\n",
    "        # ë³‘í•©í•œ vector ì°¨ì› ì¶•ì†Œ\n",
    "        outputs = self.classifier(features)\n",
    "\n",
    "        # Loss ê³„ì‚°\n",
    "        loss_fct = nn.CrossEntropyLoss()\n",
    "        loss = loss_fct(outputs, answer.view(-1))\n",
    "\n",
    "        return {\"loss\": loss}\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KorNLI Data ë¶ˆëŸ¬ì˜¤ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sen1</th>\n",
       "      <th>sen2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>í•œ ì‚¬ëŒì´ ê²½ìŸì„ ìœ„í•´ ë§ì„ í›ˆë ¨ì‹œí‚¤ê³  ìˆë‹¤.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>í•œ ì‚¬ëŒì´ ì‹ë‹¹ì—ì„œ ì˜¤ë¯ˆë ›ì„ ì£¼ë¬¸í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>contradiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>ì‚¬ëŒì€ ì•¼ì™¸ì—ì„œ ë§ì„ íƒ€ê³  ìˆë‹¤.</td>\n",
       "      <td>entailment</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sen1                       sen2     gold_label\n",
       "0  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.  í•œ ì‚¬ëŒì´ ê²½ìŸì„ ìœ„í•´ ë§ì„ í›ˆë ¨ì‹œí‚¤ê³  ìˆë‹¤.        neutral\n",
       "1  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.   í•œ ì‚¬ëŒì´ ì‹ë‹¹ì—ì„œ ì˜¤ë¯ˆë ›ì„ ì£¼ë¬¸í•˜ê³  ìˆë‹¤.  contradiction\n",
       "2  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.         ì‚¬ëŒì€ ì•¼ì™¸ì—ì„œ ë§ì„ íƒ€ê³  ìˆë‹¤.     entailment"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "with open(\"../data/KorNLI/snli_1.0_train.ko.tsv\") as f:\n",
    "    v = f.readlines()\n",
    "\n",
    "## from list to dataframe\n",
    "lst = [i.rstrip(\"\\n\").split(\"\\t\") for i in v]\n",
    "\n",
    "data = pd.DataFrame(lst[1:], columns=lst[:1])\n",
    "data.columns = [\"sen1\", \"sen2\", \"gold_label\"]\n",
    "data.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### gold_label Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sen1</th>\n",
       "      <th>sen2</th>\n",
       "      <th>gold_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>í•œ ì‚¬ëŒì´ ê²½ìŸì„ ìœ„í•´ ë§ì„ í›ˆë ¨ì‹œí‚¤ê³  ìˆë‹¤.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>í•œ ì‚¬ëŒì´ ì‹ë‹¹ì—ì„œ ì˜¤ë¯ˆë ›ì„ ì£¼ë¬¸í•˜ê³  ìˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.</td>\n",
       "      <td>ì‚¬ëŒì€ ì•¼ì™¸ì—ì„œ ë§ì„ íƒ€ê³  ìˆë‹¤.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         sen1                       sen2  gold_label\n",
       "0  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.  í•œ ì‚¬ëŒì´ ê²½ìŸì„ ìœ„í•´ ë§ì„ í›ˆë ¨ì‹œí‚¤ê³  ìˆë‹¤.           2\n",
       "1  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.   í•œ ì‚¬ëŒì´ ì‹ë‹¹ì—ì„œ ì˜¤ë¯ˆë ›ì„ ì£¼ë¬¸í•˜ê³  ìˆë‹¤.           0\n",
       "2  ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.         ì‚¬ëŒì€ ì•¼ì™¸ì—ì„œ ë§ì„ íƒ€ê³  ìˆë‹¤.           1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2int = {\"contradiction\": 0, \"entailment\": 1, \"neutral\": 2}\n",
    "\n",
    "data[\"gold_label\"] = data[\"gold_label\"].replace(label2int).values\n",
    "\n",
    "data.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Huggingface Datasetìœ¼ë¡œ ë¶ˆëŸ¬ì˜¤ê¸°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sen1': 'ë§ì„ íƒ„ ì‚¬ëŒì´ ê³ ì¥ë‚œ ë¹„í–‰ê¸° ìœ„ë¡œ ë›°ì–´ì˜¤ë¥¸ë‹¤.',\n",
       " 'sen2': 'í•œ ì‚¬ëŒì´ ê²½ìŸì„ ìœ„í•´ ë§ì„ í›ˆë ¨ì‹œí‚¤ê³  ìˆë‹¤.',\n",
       " 'gold_label': 2}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_set = Dataset.from_pandas(data)\n",
    "\n",
    "train_data_set[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### collator êµ¬í˜„\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smart_batching_collate(batch):\n",
    "    text_lst1 = []\n",
    "    text_lst2 = []\n",
    "    labels = []\n",
    "\n",
    "    for example in batch:\n",
    "        for k, v in example.items():\n",
    "            if k == \"sen1\":\n",
    "                text_lst1.append(v)\n",
    "            if k == \"sen2\":\n",
    "                text_lst2.append(v)\n",
    "            if k == \"gold_label\":\n",
    "                labels.append(int(v))\n",
    "\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    sentence_features = []\n",
    "    for items in [text_lst1, text_lst2]:\n",
    "        tokenized = tokenizer(items, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        sentence_features.append(tokenized)\n",
    "\n",
    "    return dict(features=sentence_features, answer=labels)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤—Transformers Trainerë¥¼ í™œìš©í•´ í•™ìŠµ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trainer Option ì„¤ì •\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"test_trainer\",\n",
    "    per_device_train_batch_size=4,\n",
    "    logging_steps=10,\n",
    "    eval_steps=100,\n",
    "    num_train_epochs=2,\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "# í•™ìŠµ êµ¬ì¡° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "model_for_training = modelForClassificationTraining(sbert)\n",
    "\n",
    "# Trainer ì •ì˜\n",
    "trainer = Trainer(\n",
    "    model=model_for_training,\n",
    "    train_dataset=train_data_set,\n",
    "    args=training_args,\n",
    "    data_collator=smart_batching_collate,\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b2097164ba635ebffc0e3795dc845ae25b57eedf0c1eb5773ded6aee9fc1b279"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
